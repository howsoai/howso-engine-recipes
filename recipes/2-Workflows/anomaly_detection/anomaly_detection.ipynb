{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "## Overview \n",
    "\n",
    "In the recipe, `engine-insights.ipynb`, we demonstrated an introduction to anomaly detection. In this recipe, expand on the methods used in that recipe. Howso Engine can be used to identify anomalous cases in a dataset and also explain why those cases may be anomalous. Furthermore, we can leverage other tools we learned in previous recipes, such  as influential and boundary cases, to provide additional context.\n",
    "\n",
    "Finding anomalous cases has value in both model building and data exploration. For example, as we continue to build a suitable model for the `Adult` datset, detecting anomalies can give us insight into whether we need to clean the dataset to reduce false signals. Possible sources of anomalies could be cases that are erroneous or falsified.   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load, Train, Analyze\n",
    "\n",
    "For questions about the specific steps of this section, please see the [basic workflow guide](https://docs.howso.com/user_guide/basics/basic_workflow.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:23.309565Z",
     "iopub.status.busy": "2025-01-29T22:50:23.309204Z",
     "iopub.status.idle": "2025-01-29T22:50:28.977921Z",
     "shell.execute_reply": "2025-01-29T22:50:28.977234Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from pmlb import fetch_data\n",
    "\n",
    "from howso.engine import Trainee\n",
    "from howso.utilities import infer_feature_attributes\n",
    "from howso.visuals import plot_anomalies\n",
    "\n",
    "pio.renderers.default = os.getenv(\"HOWSO_RECIPE_RENDERER\", \"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Data and Create Trainee\n",
    "\n",
    "Our example dataset for this recipe continues to be the well known `Adult` dataset. This dataset consists of 14 Context Features and 1 Action Feature. The Action Feature in this version of the `Adult` dataset has been renamed to `target` and it takes the form of a binary indicator for whether a person in the data makes over $50,000/year (*target*=1) or less (*target*=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:28.980438Z",
     "iopub.status.busy": "2025-01-29T22:50:28.980220Z",
     "iopub.status.idle": "2025-01-29T22:50:30.998669Z",
     "shell.execute_reply": "2025-01-29T22:50:30.997993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following parameters from your configuration will override the default Amalgam parameters: {'library_path', 'trace'}\n"
     ]
    }
   ],
   "source": [
    "df = fetch_data('adult', local_cache_dir=\"../../data/adult\")\n",
    "\n",
    "# Subsample the data to ensure the example runs quickly\n",
    "df = df.sample(1000, random_state=0)\n",
    "\n",
    "# Infer feature attributes\n",
    "features = infer_feature_attributes(df)\n",
    "\n",
    "# Create the Trainee\n",
    "t = Trainee(features=features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:31.001178Z",
     "iopub.status.busy": "2025-01-29T22:50:31.000809Z",
     "iopub.status.idle": "2025-01-29T22:50:35.627813Z",
     "shell.execute_reply": "2025-01-29T22:50:35.627202Z"
    }
   },
   "outputs": [],
   "source": [
    "t.train(df)\n",
    "\n",
    "# Targetless Analysis\n",
    "t.analyze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Anomaly Identification\n",
    "\n",
    "We will use [Familiarity Conviction](https://docs.howso.com/getting_started/terminology.html#familiarity-conviction) and [Distance Contribution](https://docs.howso.com/getting_started/terminology.html#distance-contribution) to identify potentially anomalous cases. Conviction is a value indicating how surprising a case is relative to how surprising other cases in the model are. In the case of `Familiarity Conviction`, the level of surprisal is measured by the perturbation of the probability distribution when the case is added or removed (hence the parameters: `familiarity_conviction_addition` and `familiarity_conviction_removal`).  Howso Engineâ€™s interpretability tools also enable us to understand why these cases may be anomalous and whether they are outliers and inliers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Compute Distance Contribution and Familiarity Conviction for every case\n",
    "\n",
    "The first step is to use `react_into_features` and select the metrics we want to return.\n",
    "\n",
    "`react_into_features` is a method that calculates the desired attributes for every case in the Trainee and caches those values into each case as a feature.\n",
    "\n",
    "Notably, this means that these features can then be used as context and action features, but this is only recommended for advanced use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:35.630605Z",
     "iopub.status.busy": "2025-01-29T22:50:35.630113Z",
     "iopub.status.idle": "2025-01-29T22:50:35.734119Z",
     "shell.execute_reply": "2025-01-29T22:50:35.733557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the familiarity conviction and distance contribution, this will be used to identify anomalous cases\n",
    "t.react_into_features(\n",
    "    familiarity_conviction_addition=True,\n",
    "    distance_contribution=True\n",
    ")\n",
    "\n",
    "stored_convictions = t.get_cases(\n",
    "    session=t.active_session,\n",
    "    features=df.columns.tolist() + ['familiarity_conviction_addition','.session_training_index', '.session', 'distance_contribution']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Threshold and Identify Anomalies\n",
    "\n",
    "There is no absolute threshold for what is considered to be anomalous, as anomalous behavior is a measure of surprisal. Thus, this is a lever that the user can change depending on the data. The threshold should be more or less than 1, which indicates average surprisal.\n",
    "\n",
    "We first use `familiarity_conviction_addition` to find anomalies, and then use the average `distance_contribution` to determine what type of anomaly the case is (e.g., inlier vs. outlier). Cases with large distance contributions will be considered outliers and those with\n",
    "low distance contributions will be inliers.\n",
    "\n",
    "For this data, we use a threshold of 0.75 for the Familiarity Conviction. Cases with a Familarity Conviction below this value will be considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:35.736511Z",
     "iopub.status.busy": "2025-01-29T22:50:35.736168Z",
     "iopub.status.idle": "2025-01-29T22:50:35.742041Z",
     "shell.execute_reply": "2025-01-29T22:50:35.741568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Threshold to determine which cases will be deemed anomalous\n",
    "convict_threshold = 0.75\n",
    "\n",
    "# Extract the anomalous cases\n",
    "low_convicts = stored_convictions[\n",
    "    stored_convictions['familiarity_conviction_addition'] <= convict_threshold\n",
    "].sort_values('familiarity_conviction_addition', ascending=True)\n",
    "\n",
    "# Average distance contribution will be used to determine if a case is an outlier or inlier\n",
    "average_dist_contribution = low_convicts['distance_contribution'].mean()\n",
    "\n",
    "# A case with distance contribution greater than average will be tagged as outlier, and vice versa for inliers\n",
    "cat = [\n",
    "    'inlier' if d < average_dist_contribution else\n",
    "    'outlier' for d in low_convicts['distance_contribution']\n",
    "]\n",
    "low_convicts['category'] = cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Anomaly Inspection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Inspect Outliers\n",
    "\n",
    "Typically, when we think of anomalies, we think of outliers or cases that are significantly different that the rest of the data, whether erroneous or not. Preprocessing in machine learning often involves pruning these data points as they can add undesired noise to a model. \n",
    "\n",
    "The Case Feature Residual Conviction will be used to understand why each case was anomalous.\n",
    "\n",
    "In our example use case where the `Adult` dataset is used to determine projected salary for loan applications, we want to eliminate any erroneous outliers if possible. We may also want to detect substituted values, as often times datasets may substitute special values with nominal integers. For example, blank values in an application are often coded with high integers like 99999 which can introduce noise in the dataset.\n",
    "\n",
    "### **Definitions:**\n",
    "\n",
    "**`case_feature_residual_convictions`** :  This is calculated using the local feature residuals, divided by the feature residuals of the Case to obtain the Convictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:35.743886Z",
     "iopub.status.busy": "2025-01-29T22:50:35.743547Z",
     "iopub.status.idle": "2025-01-29T22:50:35.759469Z",
     "shell.execute_reply": "2025-01-29T22:50:35.758985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "      <th>familiarity_conviction_addition</th>\n",
       "      <th>.session_training_index</th>\n",
       "      <th>.session</th>\n",
       "      <th>distance_contribution</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>126060.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152570</td>\n",
       "      <td>627</td>\n",
       "      <td>013bb08e-6989-4d00-8e0e-883f011266d7</td>\n",
       "      <td>61.145590</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>206609.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>127</td>\n",
       "      <td>013bb08e-6989-4d00-8e0e-883f011266d7</td>\n",
       "      <td>57.312088</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>257557.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187767</td>\n",
       "      <td>535</td>\n",
       "      <td>013bb08e-6989-4d00-8e0e-883f011266d7</td>\n",
       "      <td>53.708348</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0  28.0          4  126060.0         11            9.0               2   \n",
       "1  31.0          6  206609.0          0            6.0               4   \n",
       "2  67.0          4  257557.0          5            4.0               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           1             5     4    0       99999.0           0.0   \n",
       "1          14             1     4    1           0.0        2205.0   \n",
       "2          14             0     2    1       10566.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country  target  familiarity_conviction_addition  \\\n",
       "0            36.0              39       0                         0.152570   \n",
       "1            60.0              39       1                         0.169014   \n",
       "2            40.0              39       1                         0.187767   \n",
       "\n",
       "   .session_training_index                              .session  \\\n",
       "0                      627  013bb08e-6989-4d00-8e0e-883f011266d7   \n",
       "1                      127  013bb08e-6989-4d00-8e0e-883f011266d7   \n",
       "2                      535  013bb08e-6989-4d00-8e0e-883f011266d7   \n",
       "\n",
       "   distance_contribution category  \n",
       "0              61.145590  outlier  \n",
       "1              57.312088  outlier  \n",
       "2              53.708348  outlier  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the outliers cases\n",
    "outliers = low_convicts[low_convicts['category'] == 'outlier'].reset_index(drop=True)\n",
    "outliers.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Outlier Value Evaluation\n",
    "\n",
    "From the above results, we can see which cases may be anomalous, however just knowing whether a case is potentially an anomaly doesn't give us all the information we need to make an informed decision. If we are deciding whether to prune a case from our training set, often we only want to prune erroneous values. Even if a case is an anomaly in terms of distance or value, if it is valid we may still leave it in as it represents a legitimate data point. \n",
    "\n",
    "By looking at the `Case Feature Residual Convictions`, we can gain some insight as to why a case was deemed anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:50:35.796684Z",
     "iopub.status.busy": "2025-01-29T22:50:35.796256Z",
     "iopub.status.idle": "2025-01-29T22:51:23.283892Z",
     "shell.execute_reply": "2025-01-29T22:51:23.283282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackxia/src/howso-engine-py/howso/client/base.py:2071: DeprecationWarning:\n",
      "\n",
      "The detail key 'case_feature_residual_convictions_robust' is deprecated and will be removed in a future release. Use 'feature_robust_residual_convictions_for_case' instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'feature_robust_residual_convictions_for_case'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# React to get the details of each anomalous case\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#   Specify trained cases to react to with 'case_indices'\u001b[39;00m\n\u001b[1;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mreact(\n\u001b[1;32m     17\u001b[0m     case_indices\u001b[38;5;241m=\u001b[39moutliers_indices,\n\u001b[1;32m     18\u001b[0m     preserve_feature_values\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     19\u001b[0m     leave_case_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     details\u001b[38;5;241m=\u001b[39mdetails\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m outlier_case_feature_residual_convictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetails\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_robust_residual_convictions_for_case\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m )[df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feature_robust_residual_convictions_for_case'"
     ]
    }
   ],
   "source": [
    "# We add a few extra metrics for subsequent examples in this notebook\n",
    "# Get the case_feature_residual_convictions, influential_cases and boundary_cases\n",
    "details = {\n",
    "    'influential_cases': True,\n",
    "    'feature_robust_residual_convictions_for_case': True\n",
    "}\n",
    "\n",
    "# Specify outlier cases\n",
    "outliers_indices = outliers[['.session', '.session_training_index']].values\n",
    "\n",
    "# Residuals must be computed and cached for some of these details\n",
    "t.get_prediction_stats(details = {\"feature_full_residuals\": True})\n",
    "\n",
    "# React to get the details of each anomalous case\n",
    "#   Specify trained cases to react to with 'case_indices'\n",
    "results = t.react(\n",
    "    case_indices=outliers_indices,\n",
    "    preserve_feature_values=df.columns.tolist(),\n",
    "    leave_case_out=True,\n",
    "    details=details\n",
    ")\n",
    "\n",
    "outlier_case_feature_residual_convictions = pd.DataFrame(\n",
    "    results['details']['feature_robust_residual_convictions_for_case']\n",
    ")[df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:51:23.286068Z",
     "iopub.status.busy": "2025-01-29T22:51:23.285850Z",
     "iopub.status.idle": "2025-01-29T22:51:24.030528Z",
     "shell.execute_reply": "2025-01-29T22:51:24.029854Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_anomalies(outliers, outlier_case_feature_residual_convictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this chart we can see that these cases were flagged as anomalous largely because of their `capital-gain` values. Since our target variable is whether someone makes over $50,000 in salary, people with such large capital gains making less than $50,000 seems odd. In addition, values such as 99999 often indicate some sort of nominal value that may represent something other than the actual capital-gain, such as if a person did not answer. \n",
    "\n",
    "With this information, we can choose the appropriate action, whether it is recoding capital-gains, removing the cases, leaving the cases out, etc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Inspect Outliers\n",
    "\n",
    "While we generally only think of outliers when it comes to anomalies, inliers are another, more discrete, form of anomaly. Inliers are the opposite of outliers, as inliers are cases that are too [similiar](https://docs.howso.com/getting_started/terminology.html#most-similar-cases) to other points. A real world hypothetical case of an inlier would be someone submitting a false transaction date in which they tried to make the data look real by making it very similar to existing data. \n",
    "\n",
    "In our case, it may be someone in a bank who is internally falsifying applications in order to try to alter the prediction model.\n",
    "\n",
    "Just like outliers, `distance_contribution` is used to detect inliers from the anomalies detected through the use of `familiarity_conviction_addition`, except now we are looking at cases below a theshold which indicates similarity to other points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:51:24.032809Z",
     "iopub.status.busy": "2025-01-29T22:51:24.032576Z",
     "iopub.status.idle": "2025-01-29T22:51:24.048548Z",
     "shell.execute_reply": "2025-01-29T22:51:24.048038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the inlier cases\n",
    "inliers = low_convicts[low_convicts['category'] == 'inlier'].reset_index(drop=True)\n",
    "inliers.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Inlier Value Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:51:24.050373Z",
     "iopub.status.busy": "2025-01-29T22:51:24.050176Z",
     "iopub.status.idle": "2025-01-29T22:52:48.785604Z",
     "shell.execute_reply": "2025-01-29T22:52:48.785007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the inlier cases\n",
    "inliers_indices = inliers[['.session', '.session_training_index']].values\n",
    "\n",
    "# React to get the details of each case\n",
    "results = t.react(\n",
    "    case_indices=inliers_indices,\n",
    "    preserve_feature_values=df.columns.tolist(),\n",
    "    leave_case_out=True,\n",
    "    details=details\n",
    ")\n",
    "\n",
    "\n",
    "inlier_case_feature_residual_convictions = pd.DataFrame(\n",
    "    results['details']['feature_robust_residual_convictions_for_case']\n",
    ")[df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:52:48.787761Z",
     "iopub.status.busy": "2025-01-29T22:52:48.787551Z",
     "iopub.status.idle": "2025-01-29T22:52:48.942222Z",
     "shell.execute_reply": "2025-01-29T22:52:48.941673Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_anomalies(inliers, inlier_case_feature_residual_convictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart is viewed similarly to the outliers chart, however we are now examining cases that are too similar. We can see that for several cases, most features show high `feature_residual_conviction`, indicating that that feature can very easily predicted using the other features. This indicates that all these feature values are unusually predictable compared to the rest of the cases in the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Additional Ideas\n",
    "\n",
    "Here we detail some additional examples methods of diving deeper into the possible anomalies detected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:52:48.944362Z",
     "iopub.status.busy": "2025-01-29T22:52:48.944149Z",
     "iopub.status.idle": "2025-01-29T22:52:48.950088Z",
     "shell.execute_reply": "2025-01-29T22:52:48.949581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def case_explain_residuals_ratio(anomalous_df, case_feature_residual_convictions, case_ind, num_features=5):\n",
    "    \"\"\"Inspect a single case and identify which of its features are particularly anomalous.\"\"\"\n",
    "    case = anomalous_df.iloc[case_ind, : ]\n",
    "    case_num = case['.session_training_index']\n",
    "    case_df = pd.concat([case, case_feature_residual_convictions.iloc[case_ind, :]], axis=1)\n",
    "    case_df = case_df.loc[df.columns]\n",
    "    case_df.columns = ['values', 'feature_full_residual_convictions_for_case']\n",
    "    case_df = case_df.sort_values(['feature_full_residual_convictions_for_case'], ascending=True)\n",
    "    print(f'key features which caused case {case_num} to be anomalous: {case_df.head().index.tolist()}')\n",
    "    print('')\n",
    "    display(case_df.head())\n",
    "\n",
    "def get_cases(anomalous_df, results, case_ind):\n",
    "    \"\"\"Inspect a single anomalous case and display its influential and boundary cases.\"\"\"\n",
    "    case = anomalous_df.iloc[case_ind, :]\n",
    "    inf_cases = pd.DataFrame(results['details']['influential_cases'][case_ind])\n",
    "\n",
    "    print('Original Case:')\n",
    "    display(case)\n",
    "    print('')\n",
    "\n",
    "    print('Influential Cases:')\n",
    "    display(inf_cases)\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out a more detailed view of the Outlier Residual Conviction chart shown earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:52:48.951870Z",
     "iopub.status.busy": "2025-01-29T22:52:48.951674Z",
     "iopub.status.idle": "2025-01-29T22:52:48.965146Z",
     "shell.execute_reply": "2025-01-29T22:52:48.964649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print out the explanations for outliers\n",
    "for i in range(2):\n",
    "    case_explain_residuals_ratio(\n",
    "        outliers,\n",
    "        outlier_case_feature_residual_convictions,\n",
    "        i\n",
    "    )\n",
    "    print('_____________')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influential cases\n",
    "\n",
    "[Influential Cases](https://docs.howso.com/getting_started/terminology.html#influential-cases) may also provide additional clues into potentially anomalous data. If a case's influential cases do not well represent itself, then this indicates there are no cases in the model that well represent the anomalous cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T22:52:48.966943Z",
     "iopub.status.busy": "2025-01-29T22:52:48.966750Z",
     "iopub.status.idle": "2025-01-29T22:52:48.988829Z",
     "shell.execute_reply": "2025-01-29T22:52:48.988324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print influential and boundary case outliers\n",
    "for i in range(2):\n",
    "    get_cases(outliers, results, i)\n",
    "    print('_____________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine_rec_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
