{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "## Overview \n",
    "\n",
    "In the recipe, `engine-insights.ipynb`, we demonstrated an introduction to anomaly detection. In this recipe, expand on the methods used in that recipe. Howso Engine can be used to identify anomalous cases in a dataset and also explain why those cases may be anomalous. Furthermore, we can leverage other tools we learned in previous recipes, such  as influential and boundary cases, to provide additional context.\n",
    "\n",
    "Finding anomalous cases has value in both model building and data exploration. For example, as we continue to build a suitable model for the `Adult` datset, detecting anomalies can give us insight into whether we need to clean the dataset to reduce false signals. Possible sources of anomalies could be cases that are erroneous or falsified.   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load, Train, Analyze\n",
    "\n",
    "For questions about the specific steps of this section, please see the [basic workflow guide](https://docs.howso.com/en/release-latest/user_guide/basic_capabilities/basic_workflow.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:31.512159Z",
     "iopub.status.busy": "2025-07-16T16:24:31.511929Z",
     "iopub.status.idle": "2025-07-16T16:24:37.308692Z",
     "shell.execute_reply": "2025-07-16T16:24:37.307992Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmlb import fetch_data\n",
    "\n",
    "from howso.engine import Trainee\n",
    "from howso.utilities import infer_feature_attributes\n",
    "from howso.visuals import plot_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Data and Create Trainee\n",
    "\n",
    "Our example dataset for this recipe continues to be the well known `Adult` dataset. This dataset consists of 14 Context Features and 1 Action Feature. The Action Feature in this version of the `Adult` dataset has been renamed to `target` and it takes the form of a binary indicator for whether a person in the data makes over $50,000/year (*target*=1) or less (*target*=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:37.311375Z",
     "iopub.status.busy": "2025-07-16T16:24:37.311159Z",
     "iopub.status.idle": "2025-07-16T16:24:39.501388Z",
     "shell.execute_reply": "2025-07-16T16:24:39.500715Z"
    }
   },
   "outputs": [],
   "source": [
    "df = fetch_data('adult', local_cache_dir=\"../../data/adult\")\n",
    "\n",
    "# Subsample the data to ensure the example runs quickly\n",
    "df = df.sample(1000, random_state=0)\n",
    "\n",
    "# Infer feature attributes\n",
    "features = infer_feature_attributes(df)\n",
    "\n",
    "# Create the Trainee\n",
    "t = Trainee(features=features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:39.503976Z",
     "iopub.status.busy": "2025-07-16T16:24:39.503708Z",
     "iopub.status.idle": "2025-07-16T16:24:49.157346Z",
     "shell.execute_reply": "2025-07-16T16:24:49.156689Z"
    }
   },
   "outputs": [],
   "source": [
    "t.train(df)\n",
    "\n",
    "# Targetless Analysis\n",
    "t.analyze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Anomaly Identification\n",
    "\n",
    "We will use [Familiarity Conviction](https://docs.howso.com/en/release-latest/getting_started/terminology.html#familiarity-conviction) and [Distance Contribution](https://docs.howso.com/en/release-latest/getting_started/terminology.html#distance-contribution) to identify potentially anomalous cases. Conviction is a value indicating how surprising a case is relative to how surprising other cases in the model are. In the case of `Familiarity Conviction`, the level of surprisal is measured by the perturbation of the probability distribution when the case is added or removed (hence the parameters: `familiarity_conviction_addition` and `familiarity_conviction_removal`).  Howso Engineâ€™s interpretability tools also enable us to understand why these cases may be anomalous and whether they are outliers and inliers. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Compute Distance Contribution and Familiarity Conviction for every case\n",
    "\n",
    "The first step is to use `react_into_features` and select the metrics we want to return.\n",
    "\n",
    "`react_into_features` is a method that calculates the desired attributes for every case in the Trainee and caches those values into each case as a feature.\n",
    "\n",
    "Notably, this means that these features can then be used as context and action features, but this is only recommended for advanced use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:49.160179Z",
     "iopub.status.busy": "2025-07-16T16:24:49.159610Z",
     "iopub.status.idle": "2025-07-16T16:24:49.244974Z",
     "shell.execute_reply": "2025-07-16T16:24:49.244106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the familiarity conviction and distance contribution, this will be used to identify anomalous cases\n",
    "t.react_into_features(\n",
    "    familiarity_conviction_addition=True,\n",
    "    distance_contribution=True\n",
    ")\n",
    "\n",
    "stored_convictions = t.get_cases(\n",
    "    session=t.active_session,\n",
    "    features=df.columns.tolist() + ['familiarity_conviction_addition','.session_training_index', '.session', 'distance_contribution']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set Threshold and Identify Anomalies\n",
    "\n",
    "There is no absolute threshold for what is considered to be anomalous, as anomalous behavior is a measure of surprisal. Thus, this is a lever that the user can change depending on the data. The threshold should be more or less than 1, which indicates average surprisal.\n",
    "\n",
    "We first use `familiarity_conviction_addition` to find anomalies, and then use the average `distance_contribution` to determine what type of anomaly the case is (e.g., inlier vs. outlier). Cases with large distance contributions will be considered outliers and those with\n",
    "low distance contributions will be inliers.\n",
    "\n",
    "For this data, we use a threshold of 0.75 for the Familiarity Conviction. Cases with a Familarity Conviction below this value will be considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:49.247322Z",
     "iopub.status.busy": "2025-07-16T16:24:49.247132Z",
     "iopub.status.idle": "2025-07-16T16:24:49.253015Z",
     "shell.execute_reply": "2025-07-16T16:24:49.252490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Threshold to determine which cases will be deemed anomalous\n",
    "convict_threshold = 0.75\n",
    "\n",
    "# Extract the anomalous cases\n",
    "low_convicts = stored_convictions[\n",
    "    stored_convictions['familiarity_conviction_addition'] <= convict_threshold\n",
    "].sort_values('familiarity_conviction_addition', ascending=True)\n",
    "\n",
    "# Average distance contribution will be used to determine if a case is an outlier or inlier\n",
    "average_dist_contribution = low_convicts['distance_contribution'].mean()\n",
    "\n",
    "# A case with distance contribution greater than average will be tagged as outlier, and vice versa for inliers\n",
    "cat = [\n",
    "    'inlier' if d < average_dist_contribution else\n",
    "    'outlier' for d in low_convicts['distance_contribution']\n",
    "]\n",
    "low_convicts['category'] = cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Anomaly Inspection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Inspect Outliers\n",
    "\n",
    "Typically, when we think of anomalies, we think of outliers or cases that are significantly different that the rest of the data, whether erroneous or not. Preprocessing in machine learning often involves pruning these data points as they can add undesired noise to a model. \n",
    "\n",
    "The Case Feature Residual Conviction will be used to understand why each case was anomalous.\n",
    "\n",
    "In our example use case where the `Adult` dataset is used to determine projected salary for loan applications, we want to eliminate any erroneous outliers if possible. We may also want to detect substituted values, as often times datasets may substitute special values with nominal integers. For example, blank values in an application are often coded with high integers like 99999 which can introduce noise in the dataset.\n",
    "\n",
    "### **Definitions:**\n",
    "\n",
    "**`case_feature_residual_convictions`** :  This is calculated using the local feature residuals, divided by the feature residuals of the Case to obtain the Convictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:49.254794Z",
     "iopub.status.busy": "2025-07-16T16:24:49.254609Z",
     "iopub.status.idle": "2025-07-16T16:24:49.271163Z",
     "shell.execute_reply": "2025-07-16T16:24:49.270619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "      <th>familiarity_conviction_addition</th>\n",
       "      <th>.session_training_index</th>\n",
       "      <th>.session</th>\n",
       "      <th>distance_contribution</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>193598.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020020</td>\n",
       "      <td>540</td>\n",
       "      <td>bf00337d-e309-429e-aacd-530579bd78c3</td>\n",
       "      <td>306.265156</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>240049.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>732</td>\n",
       "      <td>bf00337d-e309-429e-aacd-530579bd78c3</td>\n",
       "      <td>280.379224</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>5</td>\n",
       "      <td>184965.0</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>649</td>\n",
       "      <td>bf00337d-e309-429e-aacd-530579bd78c3</td>\n",
       "      <td>387.300496</td>\n",
       "      <td>outlier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0  30.0          4  193598.0         13            1.0               4   \n",
       "1  23.0          4  240049.0         13            1.0               4   \n",
       "2  65.0          5  184965.0         10           16.0               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           5             1     4    1           0.0           0.0   \n",
       "1           8             1     1    0           0.0           0.0   \n",
       "2           4             0     4    1       99999.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country  target  familiarity_conviction_addition  \\\n",
       "0            40.0              26       1                         0.020020   \n",
       "1            40.0              25       1                         0.023356   \n",
       "2            40.0              39       0                         0.025733   \n",
       "\n",
       "   .session_training_index                              .session  \\\n",
       "0                      540  bf00337d-e309-429e-aacd-530579bd78c3   \n",
       "1                      732  bf00337d-e309-429e-aacd-530579bd78c3   \n",
       "2                      649  bf00337d-e309-429e-aacd-530579bd78c3   \n",
       "\n",
       "   distance_contribution category  \n",
       "0             306.265156  outlier  \n",
       "1             280.379224  outlier  \n",
       "2             387.300496  outlier  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the outliers cases\n",
    "outliers = low_convicts[low_convicts['category'] == 'outlier'].reset_index(drop=True)\n",
    "outliers.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Outlier Value Evaluation\n",
    "\n",
    "From the above results, we can see which cases may be anomalous, however just knowing whether a case is potentially an anomaly doesn't give us all the information we need to make an informed decision. If we are deciding whether to prune a case from our training set, often we only want to prune erroneous values. Even if a case is an anomaly in terms of distance or value, if it is valid we may still leave it in as it represents a legitimate data point. \n",
    "\n",
    "By looking at the `Case Feature Residual Convictions`, we can gain some insight as to why a case was deemed anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:49.307938Z",
     "iopub.status.busy": "2025-07-16T16:24:49.307495Z",
     "iopub.status.idle": "2025-07-16T16:24:51.543117Z",
     "shell.execute_reply": "2025-07-16T16:24:51.542494Z"
    }
   },
   "outputs": [],
   "source": [
    "# We add a few extra metrics for subsequent examples in this notebook\n",
    "# Get the case_feature_residual_convictions, influential_cases and boundary_cases\n",
    "details = {\n",
    "    'influential_cases': True,\n",
    "    'feature_full_residual_convictions_for_case': True\n",
    "}\n",
    "\n",
    "# Specify outlier cases\n",
    "outliers_indices = outliers[['.session', '.session_training_index']].values\n",
    "\n",
    "# Residuals must be computed and cached for some of these details\n",
    "t.get_prediction_stats(details = {\"feature_full_residuals\": True})\n",
    "\n",
    "# React to get the details of each anomalous case\n",
    "#   Specify trained cases to react to with 'case_indices'\n",
    "results = t.react(\n",
    "    case_indices=outliers_indices,\n",
    "    preserve_feature_values=df.columns.tolist(),\n",
    "    leave_case_out=True,\n",
    "    details=details\n",
    ")\n",
    "\n",
    "outlier_case_feature_residual_convictions = pd.DataFrame(\n",
    "    results['details']['feature_full_residual_convictions_for_case']\n",
    ")[df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:51.545593Z",
     "iopub.status.busy": "2025-07-16T16:24:51.545382Z",
     "iopub.status.idle": "2025-07-16T16:24:52.282832Z",
     "shell.execute_reply": "2025-07-16T16:24:52.282179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\io\\_base_renderers.py:123: DeprecationWarning:\n",
      "\n",
      "\n",
      "Support for the 'engine' argument is deprecated and will be removed after September 2025.\n",
      "Kaleido will be the only supported engine at that time.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nImage export using the \"kaleido\" engine requires the Kaleido package,\nwhich can be installed using pip:\n\n    $ pip install --upgrade kaleido\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_anomalies(outliers, outlier_case_feature_residual_convictions)\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m750\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\basedatatypes.py:3420\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3388\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3389\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3416\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3418\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\io\\_renderers.py:407\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m fig_dict \u001b[38;5;241m=\u001b[39m validate_coerce_fig_to_dict(fig, validate)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;66;03m# Mimetype renderers\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m bundle \u001b[38;5;241m=\u001b[39m renderers\u001b[38;5;241m.\u001b[39m_build_mime_bundle(fig_dict, renderers_string\u001b[38;5;241m=\u001b[39mrenderer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bundle:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ipython_display:\n",
      "File \u001b[1;32mc:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\io\\_renderers.py:315\u001b[0m, in \u001b[0;36mRenderersConfig._build_mime_bundle\u001b[1;34m(self, fig_dict, renderers_string, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(renderer, k):\n\u001b[0;32m    313\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(renderer, k, v)\n\u001b[1;32m--> 315\u001b[0m         bundle\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_mimebundle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bundle\n",
      "File \u001b[1;32mc:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\io\\_base_renderers.py:123\u001b[0m, in \u001b[0;36mImageRenderer.to_mimebundle\u001b[1;34m(self, fig_dict)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_mimebundle\u001b[39m(\u001b[38;5;28mself\u001b[39m, fig_dict):\n\u001b[1;32m--> 123\u001b[0m     image_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb64_encode:\n\u001b[0;32m    134\u001b[0m         image_str \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(image_bytes)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JacobBeel\\miniconda3\\envs\\engine-recipes-3.10\\lib\\site-packages\\plotly\\io\\_kaleido.py:345\u001b[0m, in \u001b[0;36mto_image\u001b[1;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# Raise informative error message if Kaleido is not installed\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kaleido_available():\n\u001b[1;32m--> 345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03mImage export using the \"kaleido\" engine requires the Kaleido package,\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03mwhich can be installed using pip:\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m    $ pip install --upgrade kaleido\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m         )\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# Convert figure to dict (and validate if requested)\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     fig_dict \u001b[38;5;241m=\u001b[39m validate_coerce_fig_to_dict(fig, validate)\n",
      "\u001b[1;31mValueError\u001b[0m: \nImage export using the \"kaleido\" engine requires the Kaleido package,\nwhich can be installed using pip:\n\n    $ pip install --upgrade kaleido\n"
     ]
    }
   ],
   "source": [
    "fig = plot_anomalies(outliers, outlier_case_feature_residual_convictions)\n",
    "fig.update_layout(width=1500, height=750)\n",
    "fig.show(renderer=\"pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this chart we can see that these cases were flagged as anomalous largely because of their `capital-gain` values. Since our target variable is whether someone makes over $50,000 in salary, people with such large capital gains making less than $50,000 seems odd. In addition, values such as 99999 often indicate some sort of nominal value that may represent something other than the actual capital-gain, such as if a person did not answer. \n",
    "\n",
    "With this information, we can choose the appropriate action, whether it is recoding capital-gains, removing the cases, leaving the cases out, etc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Inspect Outliers\n",
    "\n",
    "While we generally only think of outliers when it comes to anomalies, inliers are another, more discrete, form of anomaly. Inliers are the opposite of outliers, as inliers are cases that are too [similiar](https://docs.howso.com/en/release-latest/getting_started/terminology.html#most-similar-cases) to other points. A real world hypothetical case of an inlier would be someone submitting a false transaction date in which they tried to make the data look real by making it very similar to existing data. \n",
    "\n",
    "In our case, it may be someone in a bank who is internally falsifying applications in order to try to alter the prediction model.\n",
    "\n",
    "Just like outliers, `distance_contribution` is used to detect inliers from the anomalies detected through the use of `familiarity_conviction_addition`, except now we are looking at cases below a theshold which indicates similarity to other points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:52.285143Z",
     "iopub.status.busy": "2025-07-16T16:24:52.284912Z",
     "iopub.status.idle": "2025-07-16T16:24:52.300465Z",
     "shell.execute_reply": "2025-07-16T16:24:52.299975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the inlier cases\n",
    "inliers = low_convicts[low_convicts['category'] == 'inlier'].reset_index(drop=True)\n",
    "inliers.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Inlier Value Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:52.302482Z",
     "iopub.status.busy": "2025-07-16T16:24:52.302121Z",
     "iopub.status.idle": "2025-07-16T16:24:56.213051Z",
     "shell.execute_reply": "2025-07-16T16:24:56.212371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the inlier cases\n",
    "inliers_indices = inliers[['.session', '.session_training_index']].values\n",
    "\n",
    "# React to get the details of each case\n",
    "results = t.react(\n",
    "    case_indices=inliers_indices,\n",
    "    preserve_feature_values=df.columns.tolist(),\n",
    "    leave_case_out=True,\n",
    "    details=details\n",
    ")\n",
    "\n",
    "\n",
    "inlier_case_feature_residual_convictions = pd.DataFrame(\n",
    "    results['details']['feature_full_residual_convictions_for_case']\n",
    ")[df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:56.215479Z",
     "iopub.status.busy": "2025-07-16T16:24:56.215288Z",
     "iopub.status.idle": "2025-07-16T16:24:56.344963Z",
     "shell.execute_reply": "2025-07-16T16:24:56.344355Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plot_anomalies(inliers, inlier_case_feature_residual_convictions)\n",
    "fig.update_layout(width=1500, height=750)\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart is viewed similarly to the outliers chart, however we are now examining cases that are too similar. We can see that for several cases, most features show high `feature_residual_conviction`, indicating that that feature can very easily predicted using the other features. This indicates that all these feature values are unusually predictable compared to the rest of the cases in the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Additional Ideas\n",
    "\n",
    "Here we detail some additional examples methods of diving deeper into the possible anomalies detected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:56.347004Z",
     "iopub.status.busy": "2025-07-16T16:24:56.346787Z",
     "iopub.status.idle": "2025-07-16T16:24:56.352769Z",
     "shell.execute_reply": "2025-07-16T16:24:56.352257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def case_explain_residuals_ratio(anomalous_df, case_feature_residual_convictions, case_ind, num_features=5):\n",
    "    \"\"\"Inspect a single case and identify which of its features are particularly anomalous.\"\"\"\n",
    "    case = anomalous_df.iloc[case_ind, : ]\n",
    "    case_num = case['.session_training_index']\n",
    "    case_df = pd.concat([case, case_feature_residual_convictions.iloc[case_ind, :]], axis=1)\n",
    "    case_df = case_df.loc[df.columns]\n",
    "    case_df.columns = ['values', 'feature_full_residual_convictions_for_case']\n",
    "    case_df = case_df.sort_values(['feature_full_residual_convictions_for_case'], ascending=True)\n",
    "    print(f'key features which caused case {case_num} to be anomalous: {case_df.head().index.tolist()}')\n",
    "    print('')\n",
    "    display(case_df.head())\n",
    "\n",
    "def get_cases(anomalous_df, results, case_ind):\n",
    "    \"\"\"Inspect a single anomalous case and display its influential and boundary cases.\"\"\"\n",
    "    case = anomalous_df.iloc[case_ind, :]\n",
    "    inf_cases = pd.DataFrame(results['details']['influential_cases'][case_ind])\n",
    "\n",
    "    print('Original Case:')\n",
    "    display(case)\n",
    "    print('')\n",
    "\n",
    "    print('Influential Cases:')\n",
    "    display(inf_cases)\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out a more detailed view of the Outlier Residual Conviction chart shown earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:56.354443Z",
     "iopub.status.busy": "2025-07-16T16:24:56.354259Z",
     "iopub.status.idle": "2025-07-16T16:24:56.367802Z",
     "shell.execute_reply": "2025-07-16T16:24:56.367245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print out the explanations for outliers\n",
    "for i in range(2):\n",
    "    case_explain_residuals_ratio(\n",
    "        outliers,\n",
    "        outlier_case_feature_residual_convictions,\n",
    "        i\n",
    "    )\n",
    "    print('_____________')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influential cases\n",
    "\n",
    "[Influential Cases](https://docs.howso.com/en/release-latest/getting_started/terminology.html#influential-cases) may also provide additional clues into potentially anomalous data. If a case's influential cases do not well represent itself, then this indicates there are no cases in the model that well represent the anomalous cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T16:24:56.369421Z",
     "iopub.status.busy": "2025-07-16T16:24:56.369240Z",
     "iopub.status.idle": "2025-07-16T16:24:56.391669Z",
     "shell.execute_reply": "2025-07-16T16:24:56.391165Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print influential and boundary case outliers\n",
    "for i in range(2):\n",
    "    get_cases(outliers, results, i)\n",
    "    print('_____________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine-recipes-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
